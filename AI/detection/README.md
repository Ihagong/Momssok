# ì´ë¯¸ì§€ íƒœê·¸ê¸°ëŠ¥ğŸ·

### ë‹´ë‹¹ì : ê¹€ë‹¤ì€



### íŒŒì¼ ì„¤ëª…

- `train.py` : í•™ìŠµì½”ë“œ -> gpuì„œë²„
- `server.py` : faster api ì—°ê²° ì½”ë“œ
- `faster-rcnn-model.py` : faster-rcnn ëª¨ë¸
-  `test.py` : í…ŒìŠ¤íŠ¸ ë° ìˆ˜í–‰ image to result íŒŒì´í”„ë¼ì¸
- `Epoch.${number}.pth` : numberë§Œí¼ í•™ìŠµí•œ ê°€ì¤‘ì¹˜ ì €ì¥íŒŒì¼



#### ì„ì‹œ fastAPI ì—°ê²°ê²½ë¡œ

`http://localhost:8000/tag` + image íŒŒì¼



#### â—test.pyì— return ë”•ì…”ë„ˆë¦¬ ë²„ì „, ë¦¬ìŠ¤íŠ¸ë²„ì „ ìˆìŠµë‹ˆë‹¤

--> ìˆ˜ì •í• ë•Œë§ˆë‹¤ ì—…ë°ì´íŠ¸ í•˜ê² ìŠµë‹ˆë‹¤

---

### ê¸°ìˆ  ì„¤ëª…

- RPN + Fast R-CNN = Faster R-CNN

- ê³¼ì •

  1) region proposal ì¶”ì¶œ â†’ ì „ì²´ image CNN ì—°ì‚° â†’ RoI projection, RoI Pooling

  2. classification, bounding box regression

- detectionì— ì“°ì¸ conv featureì„ RPNì—ì„œë„ ê³µìœ í•´ì„œ RoIìƒì„± ì—­ì‹œ CNN levelì—ì„œ ìˆ˜í–‰



### ì½”ë“œ ì„¤ëª…

- backbone : ì´ë¯¸ì§€ì˜ í”¼ì²˜ë§µì„ ë½‘ëŠ” ë„¤íŠ¸ì›Œí¬

  - VGG16 - faster rcnn ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬

  - Resnet50 - ì •í™•ì„±ì„ ë†’ì¸ ë„¤íŠ¸ì›Œí¬

- CosineAnnealingLR(ìŠ¤ì¼€ì¤„ëŸ¬) : ì§„ë™í•˜ëŠ” ë°©ì‹

  - ```
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,total_epoch,eta_min=0.00001)
    ```

  - total_epoch ì£¼ê¸°ë§Œí¼ eta_min ë§Œí¼ ì§„ë™

- torch.optim.SGD(ì˜µí‹°ë§ˆì´ì €): ê¸°ìš¸ê¸° ì´ë™

  - ```
    optimizer = torch.optim.SGD(params = model.parameters(),lr = 0.001, momentum = 0.9, weight_decay=0.0005)
    ```

  - ë¯¸ë¶„ê°’ì„ lrë§Œí¼ ì´ë™, momentumë§Œí¼ ê´€ì„±ì„ì£¼ì–´ ì§€ì—­í•´ì•  ë¹ ì§€ì§€ ì•Šë„ë¡ í•¨

  - Weight decayëŠ” ëª¨ë¸ì˜ weightì˜ ì œê³±í•©ì„ íŒ¨ë„í‹° í…€ìœ¼ë¡œ ì£¼ì–´ (=ì œì•½ì„ ê±¸ì–´) lossë¥¼ ìµœì†Œí™”

- anchor_generator: ë°•ìŠ¤ ìƒì„±

  - ```
    anchor_generator = torchvision.models.detection.rpn.AnchorGenerator(sizes=((128, 256, 512),),aspect_ratios=((0.5, 1.0, 2.0),))
    ```

  - anchor box size: (128, 256, 512)

  - anchor box aspect ratio: (0.5, 1.0, 2.0)

- RPN(Region Proposal Network)
  - VGG16 ë§ˆì§€ë§‰ ì°¨ì›: 512
  - Resnet50 ë§ˆì§€ë§‰ ì°¨ì›: 2048
  - ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ: ì§§ì€ ë¶€ë¶„ì„ 400 í”½ì…€ë¡œ ê³ ì •, ê¸´ ë¶€ë¶„ì€ ìµœëŒ€ 600í”½ì…€
  - Non Maximum Suppression (NMS) ì´ì „ anchor box ê°œìˆ˜: 6000
  - NMS threshold: 0.7
  - NMSì´í›„ anchor box ê°œìˆ˜: 2000(train), 300(test)
  - parameter ì´ˆê¸°í™”: í‰ê· 0, í‘œì¤€í¸ì°¨ 0.01ì˜ ê°€ìš°ìŠ¤ ë¶„í¬

- fast rcnn
  - RoI pooling layer: MultiScaleRoIAlign
  - RoI pooling size: 7x7
  - RoI head: ë‘ê°œì˜ FC layer (inputsize x 4096),(4096x4096)
  - Class ê°œìˆ˜: 23ê°œ (22ê°œ class + ë°°ê²½)
  - Batch size: 128
  - foreground threshold: 0.5
  - background threshold: 0.5
  - positive fraction: 0.25
  - parameter ì´ˆê¸°í™”: classification í‰ê·  0, í‘œì¤€í¸ì°¨ 0.01 / bounding-box regression í‰ê·  0, í‘œì¤€í¸ì°¨ 0.001 ê°€ìš°ìŠ¤ ë¶„í¬

- ì°¸ê³ 

  ```
          backbone (nn.Module): the network used to compute the features for the model.
              It should contain a out_channels attribute, which indicates the number of output
              channels that each feature map has (and it should be the same for all feature maps).
              The backbone should return a single Tensor or and OrderedDict[Tensor].
              
          num_classes (int): number of output classes of the model (including the background).
              If box_predictor is specified, num_classes should be None.
              
          min_size (int): minimum size of the image to be rescaled before feeding it to the backbone
          max_size (int): maximum size of the image to be rescaled before feeding it to the backbone
          
          image_mean (Tuple[float, float, float]): mean values used for input normalization.
              They are generally the mean values of the dataset on which the backbone has been trained
              on
              
          image_std (Tuple[float, float, float]): std values used for input normalization.
              They are generally the std values of the dataset on which the backbone has been trained on
          rpn_anchor_generator (AnchorGenerator): module that generates the anchors for a set of feature
              maps.
              
          rpn_head (nn.Module): module that computes the objectness and regression deltas from the RPN
          rpn_pre_nms_top_n_train (int): number of proposals to keep before applying NMS during training
          rpn_pre_nms_top_n_test (int): number of proposals to keep before applying NMS during testing
          rpn_post_nms_top_n_train (int): number of proposals to keep after applying NMS during training
          rpn_post_nms_top_n_test (int): number of proposals to keep after applying NMS during testing
          rpn_nms_thresh (float): NMS threshold used for postprocessing the RPN proposals
          
          rpn_fg_iou_thresh (float): minimum IoU between the anchor and the GT box so that they can be
              considered as positive during training of the RPN.
              
          rpn_bg_iou_thresh (float): maximum IoU between the anchor and the GT box so that they can be
              considered as negative during training of the RPN.
              
          rpn_batch_size_per_image (int): number of anchors that are sampled during training of the RPN
              for computing the loss
              
          rpn_positive_fraction (float): proportion of positive anchors in a mini-batch during training
              of the RPN
              
          rpn_score_thresh (float): during inference, only return proposals with a classification score
              greater than rpn_score_thresh
              
          box_roi_pool (MultiScaleRoIAlign): the module which crops and resizes the feature maps in
              the locations indicated by the bounding boxes
              
          box_head (nn.Module): module that takes the cropped feature maps as input
          box_predictor (nn.Module): module that takes the output of box_head and returns the
              classification logits and box regression deltas.
              
          box_score_thresh (float): during inference, only return proposals with a classification score
              greater than box_score_thresh
              
          box_nms_thresh (float): NMS threshold for the prediction head. Used during inference
          box_detections_per_img (int): maximum number of detections per image, for all classes.
          box_fg_iou_thresh (float): minimum IoU between the proposals and the GT box so that they can be
              considered as positive during training of the classification head
              
          box_bg_iou_thresh (float): maximum IoU between the proposals and the GT box so that they can be
              considered as negative during training of the classification head
              
          box_batch_size_per_image (int): number of proposals that are sampled during training of the
              classification head
              
          box_positive_fraction (float): proportion of positive proposals in a mini-batch during training
              of the classification head
              
          bbox_reg_weights (Tuple[float, float, float, float]): weights for the encoding/decoding of the
              bounding boxes
              
          keypoint_roi_pool (MultiScaleRoIAlign): the module which crops and resizes the feature maps in
               the locations indicated by the bounding boxes, which will be used for the keypoint head.
               
          keypoint_head (nn.Module): module that takes the cropped feature maps as input
          keypoint_predictor (nn.Module): module that takes the output of the keypoint_head and returns the
              heatmap logits
  
  ```