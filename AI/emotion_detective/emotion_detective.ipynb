{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvfgIbpxUHAR"
   },
   "source": [
    "# 필요 라이브러리 다운및 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21946,
     "status": "ok",
     "timestamp": 1664320003792,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "bICG7qFjXFMG",
    "outputId": "8e6b0166-6258-4450-9f90-58d865a49512"
   },
   "outputs": [],
   "source": [
    "# 로컬에 깔려서 버전바뀌니까 그만 까세요!\n",
    "\n",
    "# !pip install mxnet\n",
    "# !pip install gluonnlp pandas tqdm\n",
    "# !pip install sentencepiece\n",
    "# !pip install transformers==3.0.2\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9360,
     "status": "ok",
     "timestamp": 1664320013148,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "h5D6q1sLU5yp",
    "outputId": "031bf99d-976d-422e-af17-f4c51bfdfba9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3075,
     "status": "ok",
     "timestamp": 1664320016219,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "kgriUaDzU5wR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2958,
     "status": "ok",
     "timestamp": 1664320019174,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "yqPYO4v_U5t1"
   },
   "outputs": [],
   "source": [
    "from kobert import get_tokenizer\n",
    "from kobert import get_pytorch_kobert_model\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6329,
     "status": "ok",
     "timestamp": 1664320025500,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "ag8rxjQLU5rm",
    "outputId": "78b39d5c-b77b-4bb7-dbaf-3cc4ed06d31b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/jupyter-j7d203/Untitled Folder/.cache/kobert_v1.zip\n",
      "using cached model. /home/jupyter-j7d203/Untitled Folder/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2701,
     "status": "ok",
     "timestamp": 1664320028188,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "o9viOeZyV6wV",
    "outputId": "54cb171f-b78e-416f-9b74-1ac0b66a5483"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1664320028188,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "I31PWXeuIHsX",
    "outputId": "3c9e977a-0f92-4b02-909d-bd8653b0bbd8"
   },
   "outputs": [],
   "source": [
    "# cd/content/gdrive/My Drive/Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1664320028189,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "7TskbR7VIINF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcZG2f1xUNd8"
   },
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1664320028189,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "10oCNY7EU5pR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./text_data5.csv',encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1664320028190,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "MUxdaPb6U5m9",
    "outputId": "69ff9edf-c908-4db1-dc2b-f16295165e6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35510"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1664320028190,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "zoRqisZMLabS",
    "outputId": "07f09f26-86ef-4098-8783-7a7592cd2df8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 0, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1664320028191,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "0d6I960GLlxP",
    "outputId": "56171491-95c9-46cd-f756-c1414edb94a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    10953\n",
       "0     8254\n",
       "3     5824\n",
       "1     5576\n",
       "2     4903\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1664320028191,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "XOiLg_gz4FT_"
   },
   "outputs": [],
   "source": [
    "index = df[df['emotion']==5].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1664320028191,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "mUTvYRH65z7f",
    "outputId": "b510566b-64e0-44b7-da6e-ba7630c2ae0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1664320028192,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "s4rkYngu4j4H"
   },
   "outputs": [],
   "source": [
    "df = df.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1664320028193,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "ydUMFHY64kTU",
    "outputId": "11d0a378-5896-4d88-d79a-d8253ea185c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    10953\n",
       "0     8254\n",
       "3     5824\n",
       "1     5576\n",
       "2     4903\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1664320028193,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "vb0Nv0kZU5ky",
    "outputId": "7f0ae3f5-413c-427a-9a4c-61706e43e986"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10298</th>\n",
       "      <td>네? 그런 게 어딨어요?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27321</th>\n",
       "      <td>이번 프로젝트에서 멋진 선배를 만나게 되었어. 믿고 배울만한 사수를 얻은 것 같아.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>국내 최고 의사에게 치료받을 수 있게 되었어.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16553</th>\n",
       "      <td>시험 봤는데 답을 밀려 썼나 봐. 말도 안 되는 점수가 나왔어.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>나 오늘도 남자친구랑 싸우고 왔어. 벌써 몇 번째 싸우는 건지 모르겠어.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28038</th>\n",
       "      <td>이제야 노후 연금을 알아보고 준비하고 있어. 너무 늦은 건 아닐지 걱정돼.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8232</th>\n",
       "      <td>내 친구의 남자 친구가 다른 사람과 다정하게 걸어가는 모습을 봤어.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32417</th>\n",
       "      <td>친구들로부터 그녀도 나에게 관심 있어 보인다는 말을 들었어.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20363</th>\n",
       "      <td>어서, 멱살 풀고 자식아!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16170</th>\n",
       "      <td>속편한 소리하고 있으시네</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               dialog  emotion\n",
       "10298                                  네? 그런 게 어딨어요?         1\n",
       "27321  이번 프로젝트에서 멋진 선배를 만나게 되었어. 믿고 배울만한 사수를 얻은 것 같아.        3\n",
       "2341                        국내 최고 의사에게 치료받을 수 있게 되었어.        3\n",
       "16553             시험 봤는데 답을 밀려 썼나 봐. 말도 안 되는 점수가 나왔어.        4\n",
       "4442         나 오늘도 남자친구랑 싸우고 왔어. 벌써 몇 번째 싸우는 건지 모르겠어.        4\n",
       "28038       이제야 노후 연금을 알아보고 준비하고 있어. 너무 늦은 건 아닐지 걱정돼.        2\n",
       "8232            내 친구의 남자 친구가 다른 사람과 다정하게 걸어가는 모습을 봤어.        4\n",
       "32417               친구들로부터 그녀도 나에게 관심 있어 보인다는 말을 들었어.        3\n",
       "20363                                  어서, 멱살 풀고 자식아!        0\n",
       "16170                                   속편한 소리하고 있으시네        0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1664320028194,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "Sokp2zWBNCAd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:132: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:132: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/tmp/ipykernel_1656090/4290562359.py:132: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  words = [word for word in words if word is not \"\"]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "# 한글만 남기고 나머지는 삭제\n",
    "def get_only_hangul(line):\n",
    "\tparseText= re.compile('/ ^[ㄱ-ㅎㅏ-ㅣ가-힣]*$/').sub('',line)\n",
    "\n",
    "\treturn parseText\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Synonym replacement\n",
    "# Replace n words in the sentence with synonyms from wordnet\n",
    "########################################################################\n",
    "def synonym_replacement(words, n):\n",
    "\tnew_words = words.copy()\n",
    "\trandom_word_list = list(set([word for word in words]))\n",
    "\trandom.shuffle(random_word_list)\n",
    "\tnum_replaced = 0\n",
    "\tfor random_word in random_word_list:\n",
    "\t\tsynonyms = get_synonyms(random_word)\n",
    "\t\tif len(synonyms) >= 1:\n",
    "\t\t\tsynonym = random.choice(list(synonyms))\n",
    "\t\t\tnew_words = [synonym if word == random_word else word for word in new_words]\n",
    "\t\t\tnum_replaced += 1\n",
    "\t\tif num_replaced >= n:\n",
    "\t\t\tbreak\n",
    "\n",
    "\tif len(new_words) != 0:\n",
    "\t\tsentence = ' '.join(new_words)\n",
    "\t\tnew_words = sentence.split(\" \")\n",
    "\n",
    "\telse:\n",
    "\t\tnew_words = \"\"\n",
    "\n",
    "\treturn new_words\n",
    "\n",
    "\n",
    "def get_synonyms(word):\n",
    "\tsynomyms = []\n",
    "\n",
    "\ttry:\n",
    "\t\tfor syn in wordnet[word]:\n",
    "\t\t\tfor s in syn:\n",
    "\t\t\t\tsynomyms.append(s)\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\n",
    "\treturn synomyms\n",
    "\n",
    "########################################################################\n",
    "# Random deletion\n",
    "# Randomly delete words from the sentence with probability p\n",
    "########################################################################\n",
    "def random_deletion(words, p):\n",
    "\tif len(words) == 1:\n",
    "\t\treturn words\n",
    "\n",
    "\tnew_words = []\n",
    "\tfor word in words:\n",
    "\t\tr = random.uniform(0, 1)\n",
    "\t\tif r > p:\n",
    "\t\t\tnew_words.append(word)\n",
    "\n",
    "\tif len(new_words) == 0:\n",
    "\t\trand_int = random.randint(0, len(words)-1)\n",
    "\t\treturn [words[rand_int]]\n",
    "\n",
    "\treturn new_words\n",
    "\n",
    "########################################################################\n",
    "# Random swap\n",
    "# Randomly swap two words in the sentence n times\n",
    "########################################################################\n",
    "def random_swap(words, n):\n",
    "\tnew_words = words.copy()\n",
    "\tfor _ in range(n):\n",
    "\t\tnew_words = swap_word(new_words)\n",
    "\n",
    "\treturn new_words\n",
    "\n",
    "def swap_word(new_words):\n",
    "\trandom_idx_1 = random.randint(0, len(new_words)-1)\n",
    "\trandom_idx_2 = random_idx_1\n",
    "\tcounter = 0\n",
    "\n",
    "\twhile random_idx_2 == random_idx_1:\n",
    "\t\trandom_idx_2 = random.randint(0, len(new_words)-1)\n",
    "\t\tcounter += 1\n",
    "\t\tif counter > 3:\n",
    "\t\t\treturn new_words\n",
    "\n",
    "\tnew_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1]\n",
    "\treturn new_words\n",
    "\n",
    "########################################################################\n",
    "# Random insertion\n",
    "# Randomly insert n words into the sentence\n",
    "########################################################################\n",
    "def random_insertion(words, n):\n",
    "\tnew_words = words.copy()\n",
    "\tfor _ in range(n):\n",
    "\t\tadd_word(new_words)\n",
    "\t\n",
    "\treturn new_words\n",
    "\n",
    "\n",
    "def add_word(new_words):\n",
    "\tsynonyms = []\n",
    "\tcounter = 0\n",
    "\twhile len(synonyms) < 1:\n",
    "\t\tif len(new_words) >= 1:\n",
    "\t\t\trandom_word = new_words[random.randint(0, len(new_words)-1)]\n",
    "\t\t\tsynonyms = get_synonyms(random_word)\n",
    "\t\t\tcounter += 1\n",
    "\t\telse:\n",
    "\t\t\trandom_word = \"\"\n",
    "\n",
    "\t\tif counter >= 10:\n",
    "\t\t\treturn\n",
    "\t\t\n",
    "\trandom_synonym = synonyms[0]\n",
    "\trandom_idx = random.randint(0, len(new_words)-1)\n",
    "\tnew_words.insert(random_idx, random_synonym)\n",
    "\n",
    "\n",
    "\n",
    "def EDA(sentence, alpha_sr=0.1, alpha_ri=0.1, alpha_rs=0.1, p_rd=0.1, num_aug=9):\n",
    "\tsentence = get_only_hangul(sentence)\n",
    "\twords = sentence.split(' ')\n",
    "\twords = [word for word in words if word is not \"\"]\n",
    "\tnum_words = len(words)\n",
    "\n",
    "\taugmented_sentences = []\n",
    "\tnum_new_per_technique = int(num_aug/4) + 1\n",
    "\n",
    "\tn_sr = max(1, int(alpha_sr*num_words))\n",
    "\tn_ri = max(1, int(alpha_ri*num_words))\n",
    "\tn_rs = max(1, int(alpha_rs*num_words))\n",
    "\n",
    "\t# sr\n",
    "\tfor _ in range(num_new_per_technique):\n",
    "\t\ta_words = synonym_replacement(words, n_sr)\n",
    "\t\taugmented_sentences.append(' '.join(a_words))\n",
    "\n",
    "\t# ri\n",
    "\tfor _ in range(num_new_per_technique):\n",
    "\t\ta_words = random_insertion(words, n_ri)\n",
    "\t\taugmented_sentences.append(' '.join(a_words))\n",
    "\n",
    "\t# rs\n",
    "\tfor _ in range(num_new_per_technique):\n",
    "\t\ta_words = random_swap(words, n_rs)\n",
    "\t\taugmented_sentences.append(\" \".join(a_words))\n",
    "\n",
    "\t# rd\n",
    "\tfor _ in range(num_new_per_technique):\n",
    "\t\ta_words = random_deletion(words, p_rd)\n",
    "\t\taugmented_sentences.append(\" \".join(a_words))\n",
    "\n",
    "\taugmented_sentences = [get_only_hangul(sentence) for sentence in augmented_sentences]\n",
    "\trandom.shuffle(augmented_sentences)\n",
    "\n",
    "\tif num_aug >= 1:\n",
    "\t\taugmented_sentences = augmented_sentences[:num_aug]\n",
    "\telse:\n",
    "\t\tkeep_prob = num_aug / len(augmented_sentences)\n",
    "\t\taugmented_sentences = [s for s in augmented_sentences if random.uniform(0, 1) < keep_prob]\n",
    "\n",
    "\taugmented_sentences.append(sentence)\n",
    "\n",
    "\treturn augmented_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8234,
     "status": "ok",
     "timestamp": 1664320036415,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "ZENxyQ1oU5iX",
    "outputId": "01610cf2-1343-48ae-e675-05562f6fc28f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390610\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "for q,label in zip(df['dialog'], df['emotion']) :\n",
    "  data = []\n",
    "  data.append(q)\n",
    "  data.append(str(label))\n",
    "  data_list.append(data)\n",
    "  for i in EDA(q):\n",
    "    data_two = []\n",
    "    data_two.append(i)\n",
    "    data_two.append(str(label))\n",
    "    data_list.append(data_two)\n",
    "print(len(data_list))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1664320036416,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "xfp_26Rpd2bI",
    "outputId": "689285e6-8b7d-4acc-ea7d-881cf638d558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ... 그래. 알았어. 그만 하자. 내가 잘못했어. 그만해.', '4']\n",
      "['... 그래. 알았어. 그만 하자. 내가 잘못했어. 그만해.', '4']\n",
      "['..왜? ', '1']\n"
     ]
    }
   ],
   "source": [
    "print(data_list[0])\n",
    "print(data_list[1])\n",
    "print(data_list[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1664320036416,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "ALYztRKAd2Yb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_train, dataset_test = train_test_split(data_list, test_size = 0.25, random_state =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1664320036416,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "ad48r4nRd2WP",
    "outputId": "f564923c-44f2-4e90-fdcb-c4c16ec54ef5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292957\n",
      "97653\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_train))\n",
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4emMm8ajUY5S"
   },
   "source": [
    "# BERT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1664320036417,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "9D1X2yhqd2T5"
   },
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "  def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n",
    "    transform = nlp.data.BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "    self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "    self.labels = [np.int32(i[label_idx])for i in dataset]\n",
    "\n",
    "  def __getitem__(self, i):\n",
    "    return (self.sentences[i] + (self.labels[i],))\n",
    "\n",
    "  def __len__(self):\n",
    "    return(len(self.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bf3XF0dJUpMB"
   },
   "source": [
    "parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1664320036417,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "cz9lK1Asd2Ry"
   },
   "outputs": [],
   "source": [
    "max_len = 64\n",
    "batch_size = 128\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 3\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate = 5e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1664320036893,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "DPtLfhZVQ2EE",
    "outputId": "74d535e7-042d-48bf-b813-3419423d17a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 28 19:46:48 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:03:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    34W / 250W |  13025MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  On   | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    35W / 250W |   1629MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-PCIE...  On   | 00000000:05:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    35W / 250W |   1609MiB / 32768MiB |     10%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-PCIE...  On   | 00000000:0C:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    41W / 250W |   1609MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-PCIE...  On   | 00000000:0D:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    37W / 250W |   1609MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-PCIE...  On   | 00000000:14:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    36W / 250W |   1609MiB / 32768MiB |      8%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-PCIE...  On   | 00000000:15:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    35W / 250W |   1609MiB / 32768MiB |     12%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-PCIE...  On   | 00000000:1B:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    57W / 250W |   8288MiB / 32768MiB |      9%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   8  Tesla V100-PCIE...  On   | 00000000:1C:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    36W / 250W |   7997MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   9  Tesla V100-PCIE...  On   | 00000000:1D:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    24W / 250W |      8MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2325      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A   1464434      C   /opt/tljh/user/bin/python        5525MiB |\n",
      "|    0   N/A  N/A   1529994      C   /opt/tljh/user/bin/python         795MiB |\n",
      "|    0   N/A  N/A   3916638      C   python3                          6693MiB |\n",
      "|    1   N/A  N/A      2325      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A   3916638      C   python3                          1619MiB |\n",
      "|    2   N/A  N/A      2325      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A   3916638      C   python3                          1599MiB |\n",
      "|    3   N/A  N/A      2325      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A   3916638      C   python3                          1599MiB |\n",
      "|    4   N/A  N/A      2325      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    4   N/A  N/A   3916638      C   python3                          1599MiB |\n",
      "|    5   N/A  N/A      2325      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A   3916638      C   python3                          1599MiB |\n",
      "|    6   N/A  N/A      2325      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    6   N/A  N/A   3916638      C   python3                          1599MiB |\n",
      "|    7   N/A  N/A      2325      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    7   N/A  N/A   1396415      C   ...nda/envs/r-cnn/bin/python     6677MiB |\n",
      "|    7   N/A  N/A   3916638      C   python3                          1599MiB |\n",
      "|    8   N/A  N/A      2325      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    8   N/A  N/A   1295301      C   ...nda/envs/r-cnn/bin/python     7989MiB |\n",
      "|    9   N/A  N/A      2325      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7_7ymgcUufr"
   },
   "source": [
    "토큰화 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1664320036893,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "APB0cDrvd2Pr",
    "outputId": "f99aee17-782f-4b78-c30b-9d68133cf3df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/jupyter-j7d203/Untitled Folder/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1664320036893,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "wKMcXfJSd2NW"
   },
   "outputs": [],
   "source": [
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 39299,
     "status": "ok",
     "timestamp": 1664320076190,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "apTZ35lJU5gK"
   },
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1664320076191,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "b-j2dxoQgI1C",
    "outputId": "952f399c-325e-4d66-dbc3-da84e12962cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2, 1397, 1804, 2640, 6607, 7925, 7990, 5561, 1820, 2075, 7088,\n",
       "        3592, 7782, 5757, 5770, 1185, 3739, 6896, 2934,  736,  921, 1422,\n",
       "        3647, 5936, 4206, 5439, 2709,  517,   54, 1185, 5400, 1917, 5859,\n",
       "        4832, 7788,  517,   54,    3,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1], dtype=int32),\n",
       " array(38, dtype=int32),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       dtype=int32),\n",
       " 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1664320076191,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "Xp42zdj0gIyn",
    "outputId": "5f3c3a7a-5acb-4346-e2df-74cf7ad0c7e5"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njQmY1HDU1Kp"
   },
   "source": [
    "# BERT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1664320076191,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "-bmWTdNYgIwi"
   },
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=5,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        else:\n",
    "            out = pooler\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1664320076192,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "I2V7YN-WhDSD"
   },
   "outputs": [],
   "source": [
    "model = BERTClassifier(bertmodel,  dr_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1664320076192,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "Y02YFk9ohDN4"
   },
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1664320076193,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "hyt0fu2GhmHD"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1664320076193,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "_urO2RRuhmE0"
   },
   "outputs": [],
   "source": [
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1664320076193,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "JROrwnyphmCR"
   },
   "outputs": [],
   "source": [
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1664320076194,
     "user": {
      "displayName": "고광",
      "userId": "00852728744853580735"
     },
     "user_tz": -540
    },
    "id": "DQzGeUh-hl_x"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cI92-NiVB6q"
   },
   "source": [
    "# Training & save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLSfSGmoh0tY",
    "outputId": "ea2be176-980a-40dc-b89b-a55b5ff6dd70"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2289 [00:08<5:10:41,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 1.6576343774795532 train acc 0.234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 201/2289 [11:51<2:01:06,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 201 loss 1.2144496440887451 train acc 0.4005752487562189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 401/2289 [23:20<1:46:10,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 401 loss 0.8535646796226501 train acc 0.5311525872817955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 601/2289 [34:54<1:33:42,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 601 loss 0.7830262184143066 train acc 0.5929310524126455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 801/2289 [46:23<1:26:15,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 801 loss 0.6961079239845276 train acc 0.6296816479400749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 1001/2289 [57:45<1:14:38,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1001 loss 0.6315661668777466 train acc 0.6572880244755245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1201/2289 [1:09:14<1:07:02,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1201 loss 0.5081194639205933 train acc 0.67873126561199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1401/2289 [1:21:29<54:29,  3.68s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1401 loss 0.4665052890777588 train acc 0.6978776320485368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 1601/2289 [1:33:47<42:13,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1601 loss 0.4691742956638336 train acc 0.715309767332917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 1801/2289 [1:46:02<30:14,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1801 loss 0.3656575083732605 train acc 0.730479594669628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 2001/2289 [1:57:30<16:09,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 2001 loss 0.38504621386528015 train acc 0.7445964517741129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 2201/2289 [2:08:53<05:02,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 2201 loss 0.30822867155075073 train acc 0.7576385733757383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2289/2289 [2:13:52<00:00,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train acc 0.762954223565721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 763/763 [13:56<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.9236191624379697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 1/2289 [00:18<11:36:37, 18.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.27517539262771606 train acc 0.921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 201/2289 [11:58<2:01:23,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 201 loss 0.35402506589889526 train acc 0.8978933457711443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 401/2289 [23:12<1:47:20,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 401 loss 0.2394794523715973 train acc 0.9074189526184538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 601/2289 [34:37<1:35:34,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 601 loss 0.19317591190338135 train acc 0.9148164517470881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 801/2289 [46:05<1:25:31,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 801 loss 0.1489613950252533 train acc 0.9209874375780275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 1001/2289 [57:37<1:14:52,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1001 loss 0.16281798481941223 train acc 0.9258007617382618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1201/2289 [1:09:07<1:02:27,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1201 loss 0.14064104855060577 train acc 0.9297720649458784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1401/2289 [1:20:36<51:57,  3.51s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1401 loss 0.14296706020832062 train acc 0.9329608315488936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 1601/2289 [1:32:16<43:37,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1601 loss 0.10842714458703995 train acc 0.9365923641474079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 1801/2289 [1:44:37<31:12,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1801 loss 0.14785081148147583 train acc 0.93942601332593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 2001/2289 [1:56:58<17:44,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 2001 loss 0.04459410160779953 train acc 0.9421539230384808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 2201/2289 [2:09:16<05:16,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 2201 loss 0.1681458204984665 train acc 0.9446771353930031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2289/2289 [2:14:21<00:00,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 train acc 0.9455147147766081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 763/763 [16:20<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.9739988525108938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 1/2289 [00:18<11:50:01, 18.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.12537045776844025 train acc 0.9453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 201/2289 [14:07<1:58:43,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 201 loss 0.05872691795229912 train acc 0.9717428482587065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 401/2289 [25:32<1:46:11,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 401 loss 0.0612301304936409 train acc 0.973328397755611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 601/2289 [36:52<1:35:01,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 601 loss 0.04977800324559212 train acc 0.9750415973377704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 801/2289 [49:32<1:42:26,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 801 loss 0.023070136085152626 train acc 0.9763479244694132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 1001/2289 [1:02:44<1:26:15,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1001 loss 0.09496506303548813 train acc 0.977280531968032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1201/2289 [1:19:38<1:36:51,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1201 loss 0.021154439076781273 train acc 0.9782082639467111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1401/2289 [1:36:06<1:14:41,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1401 loss 0.05252206325531006 train acc 0.9788097787294789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 1601/2289 [1:55:26<58:48,  5.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1601 loss 0.019921189174056053 train acc 0.9794903575890068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 1801/2289 [2:14:06<44:28,  5.47s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1801 loss 0.015442713163793087 train acc 0.9798375902276513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 2001/2289 [2:32:32<24:49,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 2001 loss 0.021110039204359055 train acc 0.9802403485757122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 2201/2289 [2:51:21<07:22,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 2201 loss 0.1034935787320137 train acc 0.9805166685597456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2289/2289 [2:59:28<00:00,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 train acc 0.9806193467941582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 763/763 [23:43<00:00,  1.87s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.9802969154316632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long()\n",
    "        segment_ids = segment_ids.long()\n",
    "        valid_length= valid_length\n",
    "        label = label.long()\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "        token_ids = token_ids.long()\n",
    "        segment_ids = segment_ids.long()\n",
    "        label = label.long()\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ECgGHbpf08ku"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTp1jmz_VIHL"
   },
   "source": [
    "# Load Model & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "zCgcMDA1CtLy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTClassifier(bertmodel,  dr_rate=0.5)\n",
    "model.load_state_dict(torch.load('./model6.h5'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "3xRMwtC2h0rm"
   },
   "outputs": [],
   "source": [
    "def predict(predict_sentence):\n",
    "  \n",
    "  data = [predict_sentence, '0']\n",
    "  dataset_another = [data]\n",
    "\n",
    "  another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "  test_dataloader = torch.utils.data.DataLoader(another_test, batch_size = batch_size, num_workers=5)\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "    token_ids = token_ids.long()\n",
    "    segment_ids = segment_ids.long()\n",
    "\n",
    "    valid_length = valid_length\n",
    "    label = label.long()\n",
    "\n",
    "    out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "    test_eval=[]\n",
    "\n",
    "    for i in out:\n",
    "      logits = i\n",
    "      logits = logits.detach().numpy()\n",
    "    \n",
    "      if np.argmax(logits) == 0:\n",
    "        test_eval.append(\"분노\")\n",
    "      elif np.argmax(logits) == 1:\n",
    "        test_eval.append(\"놀람\")\n",
    "      elif np.argmax(logits) == 2:\n",
    "        test_eval.append(\"불안\")\n",
    "      elif np.argmax(logits) == 3:\n",
    "        test_eval.append(\"행복\")\n",
    "      elif np.argmax(logits) == 4:\n",
    "        test_eval.append(\"슬픔\")\n",
    "      # elif np.argmax(logits) == 5:\n",
    "      #   test_eval.append(\"당황이\")\n",
    "   \n",
    "#     print(\">> 입력하신 내용에서 \"+ test_eval[0] + \" 느껴집니다.\")\n",
    "#     print(min(logits))\n",
    "#     print(logits)\n",
    "    min_logits = min(logits)\n",
    "    if min_logits < 0:\n",
    "        for q in range(len(logits)):\n",
    "            logits[q]+=abs(min_logits)\n",
    "    total = sum(logits)\n",
    "    emotions_scores =[]\n",
    "    for w in range(len(logits)):\n",
    "        emotions_scores.append(round(((logits[w]/total) * 100), 2))\n",
    "#     print(emotions_scores)\n",
    "#     print(sum(emotions_scores))\n",
    "    return emotions_scores, test_eval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "VNr_5CmEh0o_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([16.36, 6.15, 0.0, 19.26, 58.24], '슬픔')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"오늘 친구들과 함께 밥을 먹었다. 내가 좋아하는 김치찌개라서 기대했는데, 엄마가 해준 김치찌개가 더 맛있어서 기대 이하였다. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Text-GG",
   "language": "python",
   "name": "text_gg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
